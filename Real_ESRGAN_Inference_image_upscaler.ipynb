{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image upscaler\n",
        "\n",
        "- Uses [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for AI image upscaling\n",
        "- Based on the colab demo available on the Real-ESRGAN repository"
      ],
      "metadata": {
        "id": "Qod83DcMhOHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating user input UI\n",
        "\n",
        "- URLs for images go in the textbox below\n",
        "- One URL per line"
      ],
      "metadata": {
        "id": "gWVfNdBEfocl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1tiyMZJW5td"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "\n",
        "import ipywidgets as wd\n",
        "\n",
        "class Models(Enum):\n",
        "  GENERAL = \"realesr-general-x4v3\"\n",
        "  REALx4 = \"RealESRGAN_x4plus\"\n",
        "  REALx2 = \"RealESRGAN_x2plus\"\n",
        "  OVERSMOOTH = \"RealESRNet_x4plus\"\n",
        "  OFFICIAL = \"official ESRGAN_x4\"\n",
        "  ANIME = \"RealESRGAN_x4plus_anime_6B\"\n",
        "  ANIMATION = \"realesr-animevideov3\"\n",
        "\n",
        "dd_model = wd.Dropdown(\n",
        "    description=\"Model: \",\n",
        "    options = [model.value for model in Models],\n",
        "    index = 0,\n",
        ")\n",
        "ft_denoise = wd.FloatText(\n",
        "    value=0,\n",
        "    description='Denoise:',\n",
        ")\n",
        "cb_face_enhance = wd.Checkbox(\n",
        "    description=\"Face-enhancement\",\n",
        "    value = False,\n",
        "    disabled = True,\n",
        ")\n",
        "cb_ceiling = wd.Checkbox(\n",
        "    description=\"Use ceiling for outscale ratio\",\n",
        "    value = False,\n",
        ")\n",
        "it_width = wd.IntText(\n",
        "    value=1920,\n",
        "    description='Width:',\n",
        ")\n",
        "it_height = wd.IntText(\n",
        "    value=1080,\n",
        "    description='Height:',\n",
        ")\n",
        "tb_scale = wd.ToggleButton(\n",
        "    value=False,\n",
        "    description=\"Use scale\",\n",
        "    tooltip=\"Use a forced scale instead of trying to reach the target resolution\",\n",
        ")\n",
        "ft_scale = wd.FloatText(\n",
        "    value=2,\n",
        "    description='Scale:',\n",
        "    disabled = True,\n",
        ")\n",
        "ta_urls = wd.Textarea(\n",
        "    placeholder=\"Type URLs for images\",\n",
        "    description=\"URLs:\",\n",
        ")\n",
        "\n",
        "def validate_denoise(current_model):\n",
        "  if current_model.new != Models.GENERAL.value:\n",
        "    ft_denoise.disabled = True\n",
        "  else:\n",
        "    ft_denoise.disabled = False\n",
        "\n",
        "def validate_face_enhance(current_model):\n",
        "  if current_model.new == Models.GENERAL.value:\n",
        "    cb_face_enhance.value = False\n",
        "    cb_face_enhance.disabled = True\n",
        "  else:\n",
        "    cb_face_enhance.disabled = False\n",
        "\n",
        "def validate_args(current_model):\n",
        "  validate_denoise(current_model)\n",
        "  validate_face_enhance(current_model)\n",
        "\n",
        "def validate_scale(scale_is_forced):\n",
        "  scale_is_forced = scale_is_forced.new\n",
        "  it_width.disabled = scale_is_forced\n",
        "  it_height.disabled = scale_is_forced\n",
        "  ft_scale.disabled = not scale_is_forced\n",
        "\n",
        "dd_model.observe(validate_args, names=\"value\")\n",
        "tb_scale.observe(validate_scale, names=\"value\")\n",
        "\n",
        "display(\n",
        "    ta_urls,\n",
        "    dd_model,\n",
        "    ft_denoise,\n",
        "    cb_face_enhance,\n",
        "    cb_ceiling,\n",
        "    wd.Label(value = \"Resolution:\"),\n",
        "    it_width,\n",
        "    it_height,\n",
        "    tb_scale,\n",
        "    ft_scale,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving images\n",
        "\n",
        "If no URLs are passed to the textbox on the UI above, an upload prompt is show to get images from the user's machine"
      ],
      "metadata": {
        "id": "vQ7Mte_NfvFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COh1bJqyzMS0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "links = ta_urls.value.splitlines()\n",
        "\n",
        "upload_folder = '/content/upload'\n",
        "result_folder = '/content/results'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "if os.path.isdir(result_folder):\n",
        "    shutil.rmtree(result_folder)\n",
        "os.mkdir(upload_folder)\n",
        "os.mkdir(result_folder)\n",
        "\n",
        "if len(links) == 0:\n",
        "  # upload images\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    dst_path = os.path.join(upload_folder, filename)\n",
        "    print(f'move {filename} to {dst_path}')\n",
        "    shutil.move(filename, dst_path)\n",
        "    if filename.endswith(\".zip\"):\n",
        "      print(f\"Decompressing {filename}\")\n",
        "      os.system(f\"unzip -j {dst_path} -d {upload_folder}\")\n",
        "      os.remove(dst_path)\n",
        "else:\n",
        "  # Download image links if set\n",
        "  for link in links:\n",
        "   !wget --directory-prefix {upload_folder} {link}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the environment"
      ],
      "metadata": {
        "id": "p6uJN-P3gbAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnpnrLfMV2jU"
      },
      "outputs": [],
      "source": [
        "!cd /content\n",
        "!rm -rf Real-ESRGAN\n",
        "# Clone Real-ESRGAN and enter the Real-ESRGAN\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yaKw7ufppPb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Set up the environment\n",
        "#!pip install facexlib\n",
        "#!pip install gfpgan\n",
        "!pip install basicsr\n",
        "!pip install -r requirements.txt\n",
        "!pip install torchvision==0.16.2\n",
        "!pip install \"numpy<2\" # Downgrade numpy because of dependencies\n",
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upscaling images"
      ],
      "metadata": {
        "id": "Q7mAO0Pbgeya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5r7WLWfgyF5"
      },
      "outputs": [],
      "source": [
        "%cd /content/Real-ESRGAN\n",
        "\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "script_path = './inference_realesrgan.py'\n",
        "dir_path = upload_folder\n",
        "image_count = len(os.listdir(dir_path))\n",
        "scale = ft_scale.value # used when target_res is None\n",
        "\n",
        "target_res = (\n",
        "     {\"width\": it_width.value, \"height\": it_height.value}\n",
        "     if not tb_scale.value\n",
        "     else None\n",
        ")\n",
        "\n",
        "args = [\n",
        "    f\"-n {dd_model.value}\",\n",
        "    # Denoise only works with the general model\n",
        "    (f\"-dn {ft_denoise.value}\" if dd_model.value == Models.GENERAL.value else \"\"),\n",
        "    (\"--face_enhance\" if cb_face_enhance.value else \"\"),\n",
        "]\n",
        "args = \" \".join(args)\n",
        "\n",
        "# If a target resolution has been set, run the upscaler individually on each\n",
        "# image to try and reach the target\n",
        "if target_res is not None:\n",
        "  # Get all images in upload dir\n",
        "  paths = [\n",
        "      os.path.join(dir_path, file)\n",
        "      for file in os.listdir(dir_path)\n",
        "      if os.path.isfile(os.path.join(dir_path, file))\n",
        "  ]\n",
        "\n",
        "  for path in paths:\n",
        "    with Image.open(path) as image:\n",
        "        width, height = image.size\n",
        "\n",
        "        w_ratio = target_res[\"width\"]/width\n",
        "        h_ratio = target_res[\"height\"]/height\n",
        "\n",
        "        scale = (max(w_ratio, h_ratio) if not cb_ceiling else math.ceil(max(w_ratio, h_ratio)))\n",
        "\n",
        "        !python {script_path} {args} -i {path} --outscale {scale}\n",
        "else:\n",
        "  !python {script_path} {args} -i {upload_folder} -o {result_folder} --outscale {scale}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying results"
      ],
      "metadata": {
        "id": "Ft3Mwn0hh7wi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IMD5vhOYp68"
      },
      "outputs": [],
      "source": [
        "# utils for visualization\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display_img(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('Real-ESRGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_list = sorted(glob.glob(os.path.join(upload_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display_img(img_input, img_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading results"
      ],
      "metadata": {
        "id": "7OigrjI2h-Ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHNHoP8PZJQ7"
      },
      "outputs": [],
      "source": [
        "# Download the results\n",
        "zip_filename = 'Real-ESRGAN_result.zip'\n",
        "if os.path.exists(zip_filename):\n",
        "  os.remove(zip_filename)\n",
        "os.system(f\"zip -r -j {zip_filename} {result_folder}/*\")\n",
        "files.download(zip_filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}